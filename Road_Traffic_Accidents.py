# -*- coding: utf-8 -*-
"""DEV_AAT_(1) (6).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h9ZP2o39z0Wi5AgzGmDuLM1b0sCdmwjz
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
import statsmodels.api as sm

path = "/content/RTA_1.csv"
da = pd.read_csv(path)

da.head()

da.shape

# Isolate the column
data = da.loc[:,('accident_reference','accident_year', 'Age', 'Sex_','Defect_of_vehicle','Accident_severity')]
data.head()

da.columns = ['Time','Day','accident_reference_number','Year','Age','Sex','Driving_experience','Type_of_vehicle','Vehicle_service_year','Defect_of_vehicle','Area_accident_occured','Types_of_Junction','Road_surface_conditions','Light_conditions','Number_of_vehicles_involved','Vehicle_movement','Cause_of_accident','Accident_severity']

da.head()

da.info()

# Check for duplicates
duplicateRowsDF = da[da.duplicated()]
duplicateRowsDF

da.drop(columns = ['accident_reference_number','Types_of_Junction','Vehicle_movement'], inplace = True)

da.head()

da.isnull().sum()

da.isnull().sum().sum()

da.count()

# Dataset before handling missing values
da.shape

da.replace(['NA', 'N/A', 'na', 'NaN', ' ', '','nan ','NAN ','Unknown','unknown','NA ','na '], np.nan, inplace=True)

# Drop the missing values
da.dropna(inplace = True)

#Dataset after missing values are dropped
da.shape

rows_with_na = da[da.isna().any(axis=1)]

# Display the rows
print(rows_with_na)

# Replace variations of 'NA', 'N/A', 'na', 'NaN', '  ' with NaN
import numpy as np

da.replace(['NA', 'N/A', 'na', 'NaN', '  ', 'NA  '], np.nan, inplace=True)

# Display rows that have any NaN values
rows_with_na = da[da.isna().any(axis=1)]

# Display the rows
rows_with_na

da.shape

# Drop rows with any NaN values directly in the da DataFrame
da.dropna(inplace=True)

# Check the shape of the cleaned DataFrame
print(da.shape)

# Descriptive analysis of numerical data
non_numerical = ['Time','Age','Driving_experience','Vehicle_service_year']
da[non_numerical].describe()

# Descriptive analysis of numerical data
numerical = ['Year','Defect_of_vehicle',]
da[numerical].describe()

fig, axs = plt.subplots(2, 2, figsize=(15, 10))

# Plot histogram and KDE for numeric variable 'Age'
sns.histplot(data=da, x="Age", kde=True, color="red", ax=axs[0, 0])
axs[0, 0].set_title("Age Distribution")

# Plot histogram and KDE for numeric variable 'Driving_experience'
sns.histplot(data=da, x="Driving_experience", kde=True, color="skyblue", ax=axs[0, 1])
axs[0, 1].set_title("Driving Experience Distribution")

# Plot histogram and KDE for numeric variable 'Vehicle_service_year'
sns.histplot(data=da, x="Vehicle_service_year", kde=True, color="green", ax=axs[1, 0])
axs[1, 0].set_title("Vehicle Service Year Distribution")

# Plot histogram and KDE for numeric variable 'Defect_of_vehicle'
sns.histplot(data=da, x="Year", kde=True, color="purple", ax=axs[1, 1])
axs[1, 1].set_title("Year Distribution")

# Adjust layout to avoid overlap
plt.tight_layout()

# Show the plot
plt.show()

# Create boxplot to observe distribution of numerical value
fig, axs = plt.subplots(2,2, figsize=(15,8))
sns.boxplot(da['Age'], ax = axs[0,0])
sns.boxplot(da['Driving_experience'], ax = axs[0,1])
sns.boxplot(da['Vehicle_service_year'], ax = axs[1,0])
sns.boxplot(da['Year'], ax = axs[1,1])

# Calculate 25th, 50th, and 75th percentiles for Driving Experience
qd25, qd50, qd75 = np.percentile(da['Driving_experience'], [25, 50, 75])

# Calculate IQR for Driving Experience
iqrd = qd75 - qd25

# Calculate the lower and upper bounds for Driving Experience
mind = qd25 - 1.5 * iqrd
maxd = qd75 + 1.5 * iqrd

# Create a new dataframe with outliers removed (without modifying the original data)
cleaned_data = da[(da['Driving_experience'] > mind) & (da['Driving_experience'] < maxd)]

# Display the size of the original and cleaned datasets
print("Original data size:", data.shape)
print("Cleaned data size:", cleaned_data.shape)

# Calculate 25th, 50th, and 75th percentiles for Vehicle Service Year
qv25, qv50, qv75 = np.percentile(da['Age'], [25, 50, 75])

# Calculate IQR for Vehicle Service Year
iqrv = qv75 - qv25

# Calculate the lower and upper bounds for Vehicle Service Year
minv = qv25 - 1.5 * iqrv
maxv = qv75 + 1.5 * iqrv

# Create a new dataframe with outliers removed for Vehicle Service Year (without modifying the original data)
cleaned_data_vehicle_service = da[(da['Vehicle_service_year'] > minv) & (da['Vehicle_service_year'] < maxv)]

# Display the size of the original and cleaned datasets
print("Original data size:", data.shape)
print("Cleaned data size for Vehicle Service Year:", cleaned_data_vehicle_service.shape)

#hot encoding
da['Defect_of_vehicle'] = da['Defect_of_vehicle'].replace({1 : 'Defect', 0 : 'No Defect'})
categorical=da['Defect_of_vehicle']
categorical.head()

da['Sex']=da['Sex'].replace({ 'Male':0 ,'Female':1})
numeric=da['Sex']
numeric.head()

unique_values = da['Accident_severity'].unique()

# Print unique values
print("Unique values:", unique_values)

unique_values = da['Area_accident_occured'].unique()

# Print unique values
print("Unique values:", unique_values)

unique_values = da['Type_of_vehicle'].unique()

# Print unique values
print("Unique values:", unique_values)

# Replace multiple categories in 'Vehicle.type' column
da['Type_of_vehicle'] = da['Type_of_vehicle'].replace(
    ['Lorry (41?100Q)', 'Lorry (11?40Q)', 'Long lorry'], 'Lorry'
).replace(
    ['Public (> 45 seats)', 'Public (13?45 seats)', 'Public (12 seats)'], 'Public'
).replace(
    ['Motorcycle', 'Bicycle', 'Bajaj'], 'Motorcycle'
)

# Print the unique values in the updated 'Vehicle.type' column
print(da['Type_of_vehicle'].unique())

# Optionally, print the entire column to inspect the updates
da['Type_of_vehicle']

# Create a copy of the 'Type_of_vehicle' column
da_copy = da.copy()

# Replace categories with numeric values
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Automobile', 1)
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Public', 2)
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Lorry', 3)
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Pick up upto 10Q', 4)
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Stationwagen', 5)
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Ridden horse', 6)
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Other', 7)
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Taxi', 8)
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Turbo', 9)
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Motorcycle', 10)
da_copy['Type_of_vehicle'] = da_copy['Type_of_vehicle'].replace('Special vehicle', 11)
da_copy['Accident_severity']=da_copy['Accident_severity'].replace('Slight Injury',1)
da_copy['Accident_severity']=da_copy['Accident_severity'].replace('Serious Injury',2)
da_copy['Accident_severity']=da_copy['Accident_severity'].replace('Fatal Injury',3)
da_copy['Day']=da_copy['Day'].replace('Sunday',1)
da_copy['Day']=da_copy['Day'].replace('Monday',2)
da_copy['Day']=da_copy['Day'].replace('Tuesday',3)
da_copy['Day']=da_copy['Day'].replace('Wednesday',4)
da_copy['Day']=da_copy['Day'].replace('Thursday',5)
da_copy['Day']=da_copy['Day'].replace('Friday',6)
da_copy['Day']=da_copy['Day'].replace('Saturday',7)
# Normalize the column to remove spaces and make matching consistent
da_copy['Area_accident_occured'] = da_copy['Area_accident_occured'].str.strip()

# Replace categories with numeric values
da_copy['Area_accident_occured'] = da_copy['Area_accident_occured'].replace({
    'Residential areas': 1,
    'Office areas': 2,
    'Recreational areas': 3,
    'Industrial areas': 4,
    'Church areas': 5,
    'Market areas': 6,
    'Rural village areas': 7,
    'Outside rural areas': 8,
    'Hospital areas': 9,
    'School areas': 10,
    'Other': 11
})

da_copy['Road_surface_conditions']=da_copy['Road_surface_conditions'].replace('Dry',0)
da_copy['Road_surface_conditions']=da_copy['Road_surface_conditions'].replace('Wet or damp',1)
da_copy['Road_surface_conditions']=da_copy['Road_surface_conditions'].replace('Snow',2)
da_copy['Light_conditions']=da_copy['Light_conditions'].replace('Daylight',0)
da_copy['Light_conditions']=da_copy['Light_conditions'].replace('Darkness - lights lit',1)
da_copy['Light_conditions']=da_copy['Light_conditions'].replace('Darkness - lights unlit',2)
da_copy['Light_conditions']=da_copy['Light_conditions'].replace('Darkness - no lighting',3)
da_copy['Accident_severity']=da_copy['Accident_severity'].replace(1,'Slight Injury')
da_copy['Accident_severity']=da_copy['Accident_severity'].replace(2,'Serious Injury')


# Check the unique values in the updated column (in the copied DataFrame)

categorical_data=da_copy[['Type_of_vehicle','Accident_severity','Day','Area_accident_occured','Road_surface_conditions','Light_conditions']]
categorical_data.head()

# Get dummies for categorical data
import pandas as pd
categorical_data=da[['Type_of_vehicle','Area_accident_occured','Accident_severity']]
dummy = pd.get_dummies(categorical_data,drop_first=True)
dummy

new_data = da.copy()  # Make a copy of the original data
new_data['Age'] = pd.cut(da['Age'], [18, 30, 40, 50, 60, 70, 80])
new_data.head()



da.dtypes

# Step 1: Convert 'Age' to numeric, setting non-numeric values to NaN
da['Age'] = pd.to_numeric(da['Age'], errors='coerce')

# Step 2: Handle NaN values, for example by dropping rows with NaN values
da = da.dropna(subset=['Age'])

# Step 3: Convert 'Age' to integer
da['Age'] = da['Age'].astype('int')

# Verify the change
print(da['Age'].dtypes)  # Should print 'int64'
da.head() # Check the first few rows to see the changes

# Group categorical data
da['Sex']=da['Sex'].replace({0:'Male' ,1:'Female'})
data_cat = da.groupby(['Age','Sex']).agg({'Accident_severity': [lambda x : np.mean(x == 'Serious Injury'), np.size]})
data_cat.columns = ['proportion','size']
data_cat

# Select numerical columns
data_num = da[['Year', 'Age', 'Sex', 'Number_of_vehicles_involved']]

# Group by Age and Sex and compute mean and standard deviation
aggregated_data = data_num.groupby(['Age', 'Sex']).agg(['mean', 'std'])

# Display the result
aggregated_data

# Group by 'Accident_severity' and 'Day', and aggregate with mean and std
aggregated_data = da.groupby(['Accident_severity', 'Day']).agg({
    'Year': ['mean', 'std'],
    'Number_of_vehicles_involved': ['mean', 'std']
})

# Display the aggregated result
aggregated_data

# Group by 'Accident_severity' and 'Road_surface_conditions', and aggregate with count and mode
aggregated_data = da.groupby(['Accident_severity', 'Road_surface_conditions']).agg({
    'Type_of_vehicle': lambda x: x.mode()[0],  # Most frequent value (mode)
    'Defect_of_vehicle': 'count',  # Number of occurrences
})

# Display the aggregated result
aggregated_data

pd.crosstab(da.Sex, da.Age)



# Pairplot of numerical variables
sns.pairplot(da, plot_kws=dict(alpha=.1, edgecolor='none'))

# Pairplot of numerical variables divided by gender
sns.pairplot(da, hue = 'Age', palette = 'husl')

# Pairplot of numerical variables divided by gender
sns.pairplot(da, hue = 'Sex', palette = 'husl')

# Pairplot of numerical variables divided by gender
sns.pairplot(da, hue = 'Driving_experience', palette = 'husl')

# # Pairplot of numerical variables divided by smoking habit
sns.pairplot(da, hue = 'Accident_severity', palette = 'Set2')

# # Pairplot of numerical variables divided by smoking habit
sns.pairplot(da, hue = 'Type_of_vehicle', palette = 'Set2')



sns.countplot(x='Accident_severity', hue='Area_accident_occured', data=da)
plt.title('Accident Severity by Area of Occurrence')
plt.show()

crosstab = pd.crosstab(da['Cause_of_accident'], da['Light_conditions'])
sns.heatmap(crosstab, annot=True, cmap='coolwarm', fmt='d')
plt.title('Cause of Accident vs Light Conditions')
plt.show()

sns.scatterplot(x='Year', y='Accident_severity', hue='Sex', data=da)
plt.title('Year vs Number of Vehicles Involved by Gender')
plt.show()

sns.pairplot(da, vars=['Year', 'Number_of_vehicles_involved'], hue='Sex', palette='Set2')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

sns.barplot(x='Type_of_vehicle', y='Number_of_vehicles_involved', hue='Road_surface_conditions', data=da)
plt.title('Average Number of Vehicles by Vehicle Type and Road Conditions')
plt.xticks(rotation=45)  # Rotate the x-axis labels by 45 degrees
plt.show()

sns.pairplot(data=da, hue='Accident_severity', vars=['Year', 'Number_of_vehicles_involved'], palette='husl')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


df = da

# Step 1: Select numerical columns
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns

# Step 2: Plot skewness for each numerical column
for col in numerical_cols:
    plt.figure(figsize=(8, 5))
    sns.histplot(df[col], kde=True, color='blue', bins=10)
    plt.title(f"Distribution of {col} (Skewness: {df[col].skew():.2f})")
    plt.xlabel(col)
    plt.ylabel("Frequency")
    plt.show()

import pandas as pd

# Assuming df is your dataset
# Selecting the numeric columns
numeric_columns = ['Year', 'Number_of_vehicles_involved', 'Age']

# Calculating skewness
skewness_values = df[numeric_columns].skew()

# Displaying skewness
print("Skewness of numerical columns:")
print(skewness_values)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming df is your dataset
numerical_cols = ['Year', 'Number_of_vehicles_involved','Age']  # Add numerical columns here

# Display kurtosis for each numerical column
print("Kurtosis of numerical columns:")
print(df[numerical_cols].kurt())

# Plot distribution with kurtosis value for each numerical column
for col in numerical_cols:
    plt.figure(figsize=(8, 5))
    sns.histplot(df[col], kde=True, color='blue', bins=10)
    kurt_value = df[col].kurt()
    plt.title(f"Distribution of {col} (Kurtosis: {kurt_value:.2f})")
    plt.xlabel(col)
    plt.ylabel("Frequency")
    plt.show()

import pandas as pd

# Assuming df is your dataset
# Selecting the numeric columns
numeric_columns = ['Year', 'Number_of_vehicles_involved', 'Age']

# Calculating skewness
skewness_values = df[numeric_columns].kurt()

# Displaying skewness
print("Skewness of numerical columns:")
print(skewness_values)

# Example for specific numeric columns
numeric_columns = ['Year', 'Age']

# Calculate mean, median, and mode for specific columns
mean_values = df[numeric_columns].mean()
median_values = df[numeric_columns].median()
mode_values = df[numeric_columns].mode()

print("Mean of selected columns:")
print(mean_values)

print("\nMedian of selected columns:")
print(median_values)

print("\nMode of selected columns:")
print(mode_values)

# Grouping by 'Area_accident_occured' and applying multiple aggregation functions
grouped_data = df.groupby('Area_accident_occured').agg({
    'Number_of_vehicles_involved': ['mean', 'sum', 'count'],
    'Year': 'median',
})

print(grouped_data)

import matplotlib.pyplot as plt

# Bar plot for accidents by area
df['Area_accident_occured'].value_counts().plot(kind='bar', color='skyblue', figsize=(8, 5))
plt.title('Number of Accidents by Area')
plt.xlabel('Area')
plt.ylabel('Number of Accidents')
plt.show()

# Creating a pivot table
pivot_table = pd.pivot_table(
    da,
    values='Number_of_vehicles_involved',  # Aggregation target
    index=['Accident_severity'],          # Rows
    columns=['Light_conditions'],         # Columns
    aggfunc='sum',                        # Aggregation function (sum in this case)
    fill_value=0                          # Replace NaN with 0
)

pivot_table

#distribution plot
sns.FacetGrid(da, height=3).map(sns.distplot, "Year").add_legend()

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(data=da, x='Type_of_vehicle')
plt.title("Count Plot of Vehicle Types")
plt.xticks(rotation=45)  # Rotate x-axis labels by 45 degrees
plt.show()

sns.scatterplot(data=da, x='Age', y='Accident_severity', hue='Sex', style='Defect_of_vehicle')
plt.title("Age vs. Accident Severity")
plt.xlabel("Age")
plt.ylabel("Accident Severity")
plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=2)  # Horizontal legend
plt.tight_layout()
plt.show()

sns.scatterplot(data=da, x='Age', y='Driving_experience', hue='Accident_severity', size='Number_of_vehicles_involved')
plt.title("Age vs. Driving Experience")
plt.xlabel("Age")
plt.ylabel("Driving Experience")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)  # Move legend outside
plt.tight_layout()
plt.show()



import seaborn as sns
import matplotlib.pyplot as plt

# Extract numerical columns for correlation
numerical_data = da[['Year', 'Age', 'Number_of_vehicles_involved']]

# Compute correlation matrix
correlation_matrix = numerical_data.corr()

# Plot the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()

da_copy.dtypes

import seaborn as sns
import matplotlib.pyplot as plt

# Select only numeric columns
numeric_columns = ['Day', 'Year', 'Age', 'Type_of_vehicle',
                   'Area_accident_occured', 'Road_surface_conditions',
                   'Light_conditions', 'Number_of_vehicles_involved']

# Compute the correlation matrix
correlation_matrix = da_copy[numeric_columns].corr()

# Plot the heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", cbar=True)
plt.title("Correlation Heatmap")
plt.show()

# Pairplot of numerical variables divided by gender
sns.pairplot(da_copy, hue = 'Accident_severity', palette = 'husl')

fig, ax = plt.subplots(1, 2, figsize=(14, 8))

# Plot 1: Bar plot for 'Day' (accidents by day of the week)
da_copy["Day"].value_counts().plot.bar(color="skyblue", ax=ax[0])
ax[0].set_title("Number of Accidents by Day")
ax[0].set_ylabel("Count")
ax[0].set_xlabel("Day of the Week")

# Plot 2: Count plot for 'Day' with 'Accident_severity' as hue
sns.countplot(x="Day", hue="Accident_severity", data=da_copy, ax=ax[1], palette='Set1')
ax[1].set_title("Accidents by Day and Severity")
ax[1].set_xlabel("Day of the Week")
ax[1].set_ylabel("Count")

plt.tight_layout()
plt.show()

fig, ax = plt.subplots(1, 2, figsize=(14, 8))

# Plot 1: Bar plot for 'Road_surface_conditions' (accidents by road surface condition)
da["Road_surface_conditions"].value_counts().plot.bar(color="skyblue", ax=ax[0])
ax[0].set_title("Number of Accidents by Road Surface Conditions")
ax[0].set_ylabel("Count")
ax[0].set_xlabel("Road Surface Conditions")

# Plot 2: Count plot for 'Road_surface_conditions' with 'Accident_severity' as hue
sns.countplot(x="Road_surface_conditions", hue="Accident_severity", data=da_copy, ax=ax[1], palette='Set1')
ax[1].set_title("Accidents by Road Surface and Severity")
ax[1].set_xlabel("Road Surface Conditions")
ax[1].set_ylabel("Count")

plt.tight_layout()
plt.show()

fig, ax = plt.subplots(1, 2, figsize=(14, 8))

# Plot 1: Bar plot for 'Number_of_vehicles_involved' (accidents by number of vehicles)
da_copy["Number_of_vehicles_involved"].value_counts().plot.bar(color="skyblue", ax=ax[0])
ax[0].set_title("Number of Accidents by Vehicles Involved")
ax[0].set_ylabel("Count")
ax[0].set_xlabel("Number of Vehicles Involved")

# Plot 2: Count plot for 'Number_of_vehicles_involved' with 'Accident_severity' as hue
sns.countplot(x="Number_of_vehicles_involved", hue="Accident_severity", data=da, ax=ax[1], palette='Set1')
ax[1].set_title("Accidents by Number of Vehicles and Severity")
ax[1].set_xlabel("Number of Vehicles Involved")
ax[1].set_ylabel("Count")

plt.tight_layout()
plt.show()

fig, ax = plt.subplots(1, 2, figsize=(14, 8))

# Plot 1: Bar plot for 'Sex' (accidents by sex)
da_copy["Sex"].value_counts().plot.bar(color="skyblue", ax=ax[0])
ax[0].set_title("Number of Accidents by Sex")
ax[0].set_ylabel("Count")
ax[0].set_xlabel("Sex")

# Plot 2: Count plot for 'Sex' with 'Accident_severity' as hue
sns.countplot(x="Sex", hue="Accident_severity", data=da_copy, ax=ax[1], palette='Set1')
ax[1].set_title("Accidents by Sex and Severity")
ax[1].set_xlabel("Sex")
ax[1].set_ylabel("Count")

plt.tight_layout()
plt.show()
